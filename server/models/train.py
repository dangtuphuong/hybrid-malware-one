import joblib
import json
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
import xgboost as xgb
from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import uuid


def train_models(file, separator, feature_columns, target_column, train_models_str='rf,xgb,hybrid'):
    option_models = train_models_str.split(',')

    try:
        # Load dataset
        data = pd.read_csv(file, sep=separator or ',')
    except FileNotFoundError:
        raise FileNotFoundError("Dataset file not found.")
    except pd.errors.EmptyDataError:
        raise ValueError("Dataset file is empty.")
    except Exception as e:
        raise ValueError(
            f"An error occurred while loading the dataset: {str(e)}")

    # Handle missing values
    data = data.ffill()

    if data.empty:
        raise ValueError(
            "No valid data available after dropping missing values.")

    # Split the data into features and target
    X = data[feature_columns].values
    y = data[target_column].values

    # Calculate and display malware type distribution
    malware_distribution = data[target_column].value_counts()
    print(f"\n### Malware Type Distribution ###\n{malware_distribution}")

    # Check if the target variable contains categorical string labels
    label_encoder = None
    if y.dtype == 'object':
        label_encoder = LabelEncoder()
        y = label_encoder.fit_transform(y)

    # Split the data into training and test sets
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=0)

    if label_encoder:
        y_test_decoded = label_encoder.inverse_transform(y_test)
    else:
        y_test_decoded = y_test

    rf_metrics = None
    xgb_metrics = None
    hybrid_metrics = None

    ### Random Forest Model ###
    if 'rf' in option_models:
        try:
            rf_model = RandomForestClassifier(
                n_estimators=200, max_depth=20, min_samples_leaf=1, min_samples_split=2, random_state=0)
            rf_model.fit(X_train, y_train)

            rf_test_preds = rf_model.predict(X_test)

            # Inverse-transform the encoded labels if necessary
            if label_encoder:
                rf_test_preds_decoded = label_encoder.inverse_transform(
                    rf_test_preds)
            else:
                rf_test_preds_decoded = rf_test_preds

            rf_metrics = {
                'accuracy': accuracy_score(y_test_decoded, rf_test_preds_decoded),
                'precision': precision_score(y_test_decoded, rf_test_preds_decoded, average='macro', zero_division=1),
                'recall': recall_score(y_test_decoded, rf_test_preds_decoded, average='macro', zero_division=1),
                'f1': f1_score(y_test_decoded, rf_test_preds_decoded, average='macro', zero_division=1),
                'classification_report': json.dumps(
                    classification_report(
                        y_test_decoded, rf_test_preds_decoded, zero_division=1, output_dict=True),
                    separators=(',', ':')
                )
            }

            print("\n### Random Forest Validation Metrics ###")
            print(f"Accuracy: {rf_metrics['accuracy']}")
            print(f"Precision: {rf_metrics['precision']}")
            print(f"Recall: {rf_metrics['recall']}")
            print(f"F1 Score: {rf_metrics['f1']}")
            print(rf_metrics['classification_report'])

        except Exception as e:
            raise ValueError(f"Error training Random Forest model: {str(e)}")

    ### XGBoost Model ###
    if 'xgb' in option_models:
        try:
            xgb_model = xgb.XGBClassifier(n_estimators=100, colsample_bytree=1.0, learning_rate=0.2,
                                          max_depth=9, subsample=0.8, eval_metric='logloss', random_state=0)
            xgb_model.fit(X_train, y_train)

            xgb_test_preds = xgb_model.predict(X_test)

            if label_encoder:
                xgb_test_preds_decoded = label_encoder.inverse_transform(
                    xgb_test_preds)
            else:
                xgb_test_preds_decoded = xgb_test_preds

            xgb_metrics = {
                'accuracy': accuracy_score(y_test_decoded, xgb_test_preds_decoded),
                'precision': precision_score(y_test_decoded, xgb_test_preds_decoded, average='macro', zero_division=1),
                'recall': recall_score(y_test_decoded, xgb_test_preds_decoded, average='macro', zero_division=1),
                'f1': f1_score(y_test_decoded, xgb_test_preds_decoded, average='macro', zero_division=1),
                'classification_report': json.dumps(
                    classification_report(
                        y_test_decoded, xgb_test_preds_decoded, zero_division=1, output_dict=True),
                    separators=(',', ':')
                )
            }

            print("\n### XGBoost Validation Metrics ###")
            print(f"Accuracy: {xgb_metrics['accuracy']}")
            print(f"Precision: {xgb_metrics['precision']}")
            print(f"Recall: {xgb_metrics['recall']}")
            print(f"F1 Score: {xgb_metrics['f1']}")
            print(xgb_metrics['classification_report'])

        except Exception as e:
            raise ValueError(f"Error training XGBoost model: {str(e)}")

    ### Hybrid Model ###
    if 'hybrid' in option_models:
        try:
            if rf_metrics:  # Only train hybrid if RF is trained
                voting_model = VotingClassifier(
                    estimators=[('rf', rf_model), ('xgb', xgb_model)], voting='hard')
                voting_model.fit(X_train, y_train)

                voting_test_preds = voting_model.predict(X_test)

                if label_encoder:
                    voting_test_preds_decoded = label_encoder.inverse_transform(
                        voting_test_preds)
                else:
                    voting_test_preds_decoded = voting_test_preds

                hybrid_metrics = {
                    'accuracy': accuracy_score(y_test_decoded, voting_test_preds_decoded),
                    'precision': precision_score(y_test_decoded, voting_test_preds_decoded, average='macro', zero_division=1),
                    'recall': recall_score(y_test_decoded, voting_test_preds_decoded, average='macro', zero_division=1),
                    'f1': f1_score(y_test_decoded, voting_test_preds_decoded, average='macro', zero_division=1),
                    'classification_report': json.dumps(
                        classification_report(
                            y_test_decoded, voting_test_preds_decoded, zero_division=1, output_dict=True),
                        separators=(',', ':')
                    )
                }

                print("\n### Hybrid Model (RF + XGBoost) ###")
                print(f"Accuracy: {hybrid_metrics['accuracy']}")
                print(f"Precision: {hybrid_metrics['precision']}")
                print(f"Recall: {hybrid_metrics['recall']}")
                print(f"F1 Score: {hybrid_metrics['f1']}")
                print(hybrid_metrics['classification_report'])

        except Exception as e:
            raise ValueError(f"Error training Hybrid model: {str(e)}")

    # Load existing models, if the file exists
    try:
        existing_models = joblib.load('models_with_ids.pkl')
    except FileNotFoundError:
        existing_models = {}

    # Define new models with unique IDs
    model_ids = {}
    if rf_metrics:
        model_ids['rf'] = str(uuid.uuid4())
        existing_models[model_ids['rf']] = {
            'model': rf_model,
            'label': 'Random Forest',
            'label_encoder': label_encoder
        }

    if xgb_metrics:
        model_ids['xgb'] = str(uuid.uuid4())
        existing_models[model_ids['xgb']] = {
            'model': xgb_model,
            'label': 'XGBoost',
            'label_encoder': label_encoder
        }

    if hybrid_metrics:
        model_ids['hybrid'] = str(uuid.uuid4())
        existing_models[model_ids['hybrid']] = {
            'model': voting_model,
            'label': 'Hybrid',
            'label_encoder': label_encoder
        }

    # Save the models with unique IDs back to the file
    joblib.dump(existing_models, 'models_with_ids.pkl')

    return malware_distribution, rf_metrics, xgb_metrics, hybrid_metrics, model_ids
