import joblib
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
import xgboost as xgb
from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split, cross_val_score
from datetime import datetime

# Get user input for the dataset path
file_path = input("Please enter the path to the dataset: ")

# Get user input for the column separator
separator = input("Please enter the column separator: ")

# Load dataset
data = pd.read_csv(file_path, sep=separator)

# Get user input for feature columns
feature_input = input(
    f"Please enter the feature columns separated by '{separator}': ")
feature_columns = [feature.strip()
                   for feature in feature_input.split(separator)]

# Get user input for target column
target_column = input("Please enter the target column name: ").strip()

# Handle missing values
data = data.ffill()

# Split the data into features and target
X = data[feature_columns]
y = data[target_column]

# Split into training and temp (validation + test) sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2)

# Split the temp set into validation and test sets
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.7)

### 2. Train and Evaluate Random Forest Model ###
rf_model = RandomForestClassifier(n_estimators=200)
rf_model.fit(X_train, y_train)

# Cross-Validation for Random Forest
rf_cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5)
print("Random Forest Cross-Validation Scores:", rf_cv_scores)

rf_train_preds = rf_model.predict(X_train)
rf_test_preds = rf_model.predict(X_test)

### Output metrics for Random Forest on Validation Set ###
rf_val_preds = rf_model.predict(X_val)
print("\n### Random Forest Validation Metrics ###")
print(f"Accuracy: {accuracy_score(y_val, rf_val_preds)}")
print(f"Precision: {precision_score(
    y_val, rf_val_preds, average='macro', zero_division=1)}")
print(f"Recall: {recall_score(
    y_val, rf_val_preds, average='macro', zero_division=1)}")
print(f"F1 Score: {
      f1_score(y_val, rf_val_preds, average='macro', zero_division=1)}")
print(classification_report(y_val, rf_val_preds, zero_division=1))

### 3. Train and Evaluate XGBoost Model ###
xgb_model = xgb.XGBClassifier(n_estimators=200)
xgb_model.fit(X_train, y_train)

# Cross-Validation for XGBoost
xgb_cv_scores = cross_val_score(xgb_model, X_train, y_train, cv=5)
print("XGBoost Cross-Validation Scores:", xgb_cv_scores)

xgb_train_preds = xgb_model.predict(X_train)
xgb_test_preds = xgb_model.predict(X_test)

### Output metrics for XGBoost on Validation Set ###
xgb_val_preds = xgb_model.predict(X_val)
print("\n### XGBoost Validation Metrics ###")
print(f"Accuracy: {accuracy_score(y_val, xgb_val_preds)}")
print(f"Precision: {precision_score(
    y_val, xgb_val_preds, average='macro', zero_division=1)}")
print(f"Recall: {recall_score(
    y_val, xgb_val_preds, average='macro', zero_division=1)}")
print(f"F1 Score: {
      f1_score(y_val, xgb_val_preds, average='macro', zero_division=1)}")
print(classification_report(y_val, xgb_val_preds, zero_division=1))

### 4. Create and Evaluate Voting Ensemble Model ###
# Define the voting ensemble model
voting_model = VotingClassifier(estimators=[
    ('rf', rf_model),
    ('xgb', xgb_model)
], voting='soft')  # Use 'soft' for probabilities or 'hard' for majority voting

# Fit the voting model
voting_model.fit(X_train, y_train)

# Cross-Validation for Voting Model
voting_cv_scores = cross_val_score(voting_model, X_val, y_val, cv=5)
print("Voting Ensemble Model Cross-Validation Scores:", voting_cv_scores)

# Predictions
voting_test_preds = voting_model.predict(X_test)

# Output metrics for Voting Model
print("\n### Voting Ensemble Model (RF + XGBoost) ###")
print(f"Accuracy: {accuracy_score(y_test, voting_test_preds)}")
print(f"Precision: {precision_score(
    y_test, voting_test_preds, average='macro', zero_division=1)}")
print(f"Recall: {recall_score(y_test, voting_test_preds,
      average='macro', zero_division=1)}")
print(f"F1 Score: {f1_score(y_test, voting_test_preds,
      average='macro', zero_division=1)}")
print(classification_report(y_test, voting_test_preds, zero_division=1))

# Load existing models, if the file exists
try:
    existing_models = joblib.load('models_with_ids.pkl')
except FileNotFoundError:
    existing_models = {}

# Function to generate a unique ID


def generate_unique_id(model_name):
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    return f"{model_name}_{timestamp}"


# Define new models with unique IDs
new_models = {
    generate_unique_id('RF'): {'model': rf_model},
    generate_unique_id('XGB'): {'model': xgb_model},
    generate_unique_id('Hybrid'): {'model': voting_model}
}

# Update existing models with new models
existing_models.update(new_models)

# Save all models back to the file
joblib.dump(existing_models, 'models_with_ids.pkl')
